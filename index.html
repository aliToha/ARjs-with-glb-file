<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta http-equiv="Content-Security-Policy" content="script-src 'unsafe-inline' 'unsafe-eval' aframe.io raw.githack.com; worker-src 'unsafe-eval' img-src 'self' a-rjs-with-glb-file.vercel.app;">
    <title>Image based tracking AR.js demo</title>
    <!-- import aframe and then ar.js with image tracking / location based features -->
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

    <!-- style for the loader -->
    <style>
      .arjs-loader {
        height: 100%;
        width: 100%;
        position: absolute;
        top: 0;
        left: 0;
        background-color: rgba(0, 0, 0, 0.8);
        z-index: 9999;
        display: flex;
        justify-content: center;
        align-items: center;
      }

      .arjs-loader div {
        text-align: center;
        font-size: 1.25em;
        color: white;
      }
    </style>
  </head>
<body>
    <!-- 
      UI Overlay: This section creates the informational box at the top-left corner.
      It's styled with Tailwind CSS classes.
    -->
    <!-- 
      A-Frame AR Scene: This is the core of the AR application.
      - `embedded`: Allows the scene to be placed within a web page.
      - `arjs`: Configures AR.js. We're using the webcam as the video source.
      - `vr-mode-ui`: We disable the VR mode button as this is an AR experience.
    -->
    <a-scene
      vr-mode-ui="enabled: false;"
      renderer="logarithmicDepthBuffer: true;"
      embedded
      arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;">
      <!-- a-nft is the anchor that defines an Image Tracking entity -->
      <!-- on 'url' use the path to the Image Descriptors created before. -->
      <!-- the path should end with the name without the extension e.g. if file is trex.fset' the path should end with trex -->
      <a-nft
        type="nft"
        url="https://a-rjs-with-glb-file.vercel.app/asset/hmns.png"
        smooth="true"
        smoothCount="10"
        smoothTolerance=".01"
        smoothThreshold="5">
          <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
          <a-entity
          gltf-model="https://a-rjs-with-glb-file.vercel.app/asset/parfume.gltf"
              scale="5 5 5"
              position="100 100 0"
          >
          </a-entity>
      </a-nft>
    <!-- static camera that moves according to the device movemenents -->
      <a-entity camera></a-entity>
    </a-scene> 
</body>
</html>
